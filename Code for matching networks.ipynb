{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Define the embedding network\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Matching Network model\n",
    "class MatchingNetwork(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(MatchingNetwork, self).__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "    \n",
    "    def forward(self, support, queries, n_way, k_shot):\n",
    "        support_embeddings = self.embedding_net(support)  # (n_way*k_shot, embedding_dim)\n",
    "        query_embeddings = self.embedding_net(queries)    # (num_queries, embedding_dim)\n",
    "        \n",
    "        # Calculate the cosine similarity\n",
    "        support_embeddings = F.normalize(support_embeddings, p=2, dim=1)\n",
    "        query_embeddings = F.normalize(query_embeddings, p=2, dim=1)\n",
    "        \n",
    "        similarities = torch.matmul(query_embeddings, support_embeddings.T)  # (num_queries, n_way*k_shot)\n",
    "        \n",
    "        # Softmax over support set for each query\n",
    "        similarities = similarities.view(-1, n_way, k_shot)\n",
    "        similarities = similarities.mean(dim=2)\n",
    "        return F.log_softmax(similarities, dim=1)\n",
    "\n",
    "# Example usage\n",
    "n_way = 5\n",
    "k_shot = 5\n",
    "num_queries = 15\n",
    "input_dim = (1, 28, 28)\n",
    "\n",
    "# Create random support and query sets\n",
    "support_set = torch.rand(n_way * k_shot, *input_dim)\n",
    "query_set = torch.rand(num_queries, *input_dim)\n",
    "labels = torch.randint(0, n_way, (num_queries,))\n",
    "\n",
    "embedding_net = EmbeddingNet()\n",
    "model = MatchingNetwork(embedding_net)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training step\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "log_probs = model(support_set, query_set, n_way, k_shot)\n",
    "loss = F.nll_loss(log_probs, labels)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Testing step\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    log_probs = model(support_set, query_set, n_way, k_shot)\n",
    "    pred_labels = torch.argmax(log_probs, dim=1)\n",
    "    accuracy = (pred_labels == labels).float().mean()\n",
    "    print(f'Accuracy: {accuracy.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
